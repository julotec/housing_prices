{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\n\ndef linear_regression_hypothesis(X, theta):\n\n    h = np.dot(X, theta)\n    return h",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "def compute_cost(X, y, theta):\n    m = len(y)\n    h = linear_regression_hypothesis(X, theta)\n    J = np.sum((h - y) **2)/(2*m)\n    return J\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "def gradient_descent_step(X, y, theta, alpha):\n    m = len(y)\n    h = linear_regression_hypothesis(X, theta)\n    gradient = np.dot(X.T, (h - y)) / m\n    theta = theta - alpha * gradient\n    return theta",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\n\n\napartments = pd.read_csv(\"Housing.csv\")\n\n\nX = apartments[[\"area\", \"bedrooms\", \"bathrooms\"]]\ny = apartments[\"price\"].values.reshape(-1, 1)\n\nX = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\ntheta = np.zeros((X.shape[1], 1))\n\n\ndef linear_regression_hypothesis(X, theta):\n    return np.dot(X, theta)\n\n\ndef compute_cost(X, y, theta):\n    m = len(y)\n    h = linear_regression_hypothesis(X, theta)\n    J = np.sum((h - y) ** 2) / (2 * m)\n    return J\n\n# Definicja algorytmu gradientowego spadku\ndef gradient_descent(X, y, theta, alpha, num_iterations):\n    m = len(y)\n    J_history = []\n    for _ in range(num_iterations):\n        h = linear_regression_hypothesis(X, theta)\n        gradient = np.dot(X.T, (h - y)) / m\n        theta -= alpha * gradient\n        J_history.append(compute_cost(X, y, theta))\n    return theta, J_history\n\n\nalpha = 0.01  # Współczynnik uczenia\nnum_iterations = 1000  # Liczba iteracji\n\ntheta_optimal, J_history = gradient_descent(X, y, theta, alpha, num_iterations)\n\nprint(\"Optymalne parametry theta:\")\nprint(f\"Współczynnik dla cechy 'area': {theta_optimal[0][0]}\")\nprint(f\"Współczynnik dla cechy 'bedrooms': {theta_optimal[1][0]}\")\nprint(f\"Współczynnik dla cechy 'bathrooms': {theta_optimal[2][0]}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Optymalne parametry theta:\nWspółczynnik dla cechy 'area': 821199.2670986366\nWspółczynnik dla cechy 'bedrooms': 300296.2856063652\nWspółczynnik dla cechy 'bathrooms': 695515.9962379065\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\n\n\nX_with_intercept = np.c_[np.ones((X.shape[0], 1)), X]\n\n\ntheta_analytical = np.linalg.inv(X_with_intercept.T.dot(X_with_intercept)).dot(X_with_intercept.T).dot(y)\n\nprint(\"Optymalne parametry theta (rozwiązanie analityczne):\")\nprint(theta_analytical)",
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Optymalne parametry theta (rozwiązanie analityczne):\n[[4766729.24770643]\n [ 821214.14349518]\n [ 299983.57107963]\n [ 695808.52272538]]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": "# Wyświetlenie wyników\nprint(\"Optymalne parametry theta uzyskane przez gradientowy spadek:\")\nprint(theta_optimal)\nprint(\"\\nOptymalne parametry theta uzyskane analitycznie:\")\nprint(theta_analytical)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Optymalne parametry theta uzyskane przez gradientowy spadek:\n[[821199.26709864]\n [300296.28560637]\n [695515.99623791]]\n\nOptymalne parametry theta uzyskane analitycznie:\n[[4766729.24770643]\n [ 821214.14349518]\n [ 299983.57107963]\n [ 695808.52272538]]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}